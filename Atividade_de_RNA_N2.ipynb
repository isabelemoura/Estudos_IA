{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHpKJEmSIvmeqxYM4cbcjt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isabelemoura/Estudos_IA/blob/main/Atividade_de_RNA_N2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge--kuSebqPe",
        "outputId": "cfffb455-baba-4217-d6ed-1dda6d48626d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Digite x1 para o par 1: 20\n",
            "Digite x2 para o par 1: 10\n",
            "Digite x3 para o par 1: 10\n",
            "Digite o valor esperado y para o par 1: 0\n",
            "Digite x1 para o par 2: 40\n",
            "Digite x2 para o par 2: 30\n",
            "Digite x3 para o par 2: 20\n",
            "Digite o valor esperado y para o par 2: 1\n",
            "Digite x1 para o par 3: -20\n",
            "Digite x2 para o par 3: 10\n",
            "Digite x3 para o par 3: 30\n",
            "Digite o valor esperado y para o par 3: 1\n",
            "Usar bias? (sim/nao): sim\n",
            "Digite a taxa de aprendizagem: 0.3\n",
            "Pesos após o treinamento: [-5.9839349  12.03782311 -2.35960198 -1.75178902]\n",
            "Número de iterações: 12\n",
            "Digite novos valores de teste (separados por vírgula) ou 'sair' para finalizar: sair\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Função de ativação degrau\n",
        "def funcao_degrau(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "# Função de treinamento do Perceptron\n",
        "def treinar_perceptron(X, y, taxa_aprendizagem, usar_bias=True, max_iteracoes=1000):\n",
        "    num_features = X.shape[1]\n",
        "    # Inicializa os pesos com valores pequenos aleatórios\n",
        "    pesos = np.random.rand(num_features + int(usar_bias))  # Inclui espaço para o bias, se necessário\n",
        "    iteracoes = 0\n",
        "    while iteracoes < max_iteracoes:\n",
        "        erro_global = 0\n",
        "        for xi, target in zip(X, y):\n",
        "            if usar_bias:\n",
        "                xi = np.append(xi, 1)  # Adiciona o bias (1) ao vetor de entrada\n",
        "            entrada_liquida = np.dot(xi, pesos)\n",
        "            saida = funcao_degrau(entrada_liquida)\n",
        "            erro = target - saida\n",
        "            pesos += taxa_aprendizagem * erro * xi\n",
        "            erro_global += abs(erro)\n",
        "        iteracoes += 1\n",
        "        if erro_global == 0:\n",
        "            break\n",
        "    return pesos, iteracoes\n",
        "\n",
        "# Função para testar novos valores de entrada\n",
        "def testar_perceptron(pesos, X, usar_bias=True):\n",
        "    resultados = []\n",
        "    for xi in X:\n",
        "        if usar_bias:\n",
        "            xi = np.append(xi, 1)  # Adiciona o bias (1) ao vetor de entrada\n",
        "        entrada_liquida = np.dot(xi, pesos)\n",
        "        saida = funcao_degrau(entrada_liquida)\n",
        "        resultados.append(saida)\n",
        "    return resultados\n",
        "\n",
        "# Função principal\n",
        "def main():\n",
        "    # Entradas de treinamento\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(3):\n",
        "        x1 = float(input(f\"Digite x1 para o par {i+1}: \"))\n",
        "        x2 = float(input(f\"Digite x2 para o par {i+1}: \"))\n",
        "        x3 = float(input(f\"Digite x3 para o par {i+1}: \"))\n",
        "        X.append([x1, x2, x3])\n",
        "        yk = int(input(f\"Digite o valor esperado y para o par {i+1}: \"))\n",
        "        y.append(yk)\n",
        "\n",
        "    usar_bias = input(\"Usar bias? (sim/nao): \").strip().lower() == \"sim\"\n",
        "    taxa_aprendizagem = float(input(\"Digite a taxa de aprendizagem: \"))\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Treinamento do Perceptron\n",
        "    pesos, iteracoes = treinar_perceptron(X, y, taxa_aprendizagem, usar_bias)\n",
        "\n",
        "    print(f\"Pesos após o treinamento: {pesos}\")\n",
        "    print(f\"Número de iterações: {iteracoes}\")\n",
        "\n",
        "    # Teste com novos valores de entrada\n",
        "    while True:\n",
        "        teste_entrada = input(\"Digite novos valores de teste (separados por vírgula) ou 'sair' para finalizar: \").strip()\n",
        "        if teste_entrada.lower() == 'sair':\n",
        "            break\n",
        "        try:\n",
        "            valores_teste = np.array([float(val) for val in teste_entrada.split(',')])\n",
        "            if len(valores_teste) != 3:\n",
        "                print(\"Por favor, insira exatamente 3 valores.\")\n",
        "                continue\n",
        "            resultado = testar_perceptron(pesos, [valores_teste], usar_bias)\n",
        "            print(f\"Saída para {valores_teste} é: {resultado[0]}\")\n",
        "        except ValueError:\n",
        "            print(\"Por favor, insira valores numéricos válidos.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}